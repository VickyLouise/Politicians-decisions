{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making TFIDF of speeches and CRS reports\n",
    "\n",
    "- Transform Congressional speeches into form that we can do machine learning on.\n",
    "- CRS reports are part of the TFIDF matrix in order to calculate the average similarity between each speech and a CRS report. This is one of the measures of a speech being 'evidence-based' in that I expect CRS reports to have reasonably neutral language, consider multiple perspectives and cite facts and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_file = open('speeches_cleaned.pkl', 'rb')\n",
    "speeches_cleaned = pickle.load(pkl_file)\n",
    "\n",
    "pkl_file = open('crs_reports.pkl', 'rb')\n",
    "crs_reports = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409395, 13)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_cleaned.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'text_processing.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409395\n"
     ]
    }
   ],
   "source": [
    "# Get the parts of speech of each word. This aids the lemmatisation. \n",
    "# Lemmatisation gets the root of the word so that derivations of the word are recognised as the same\n",
    "\n",
    "# Speeches\n",
    "list_sentences_pos_speeches = get_pos(list(speeches_cleaned['text']))\n",
    "lemmatized_corpus_speeches = lemmatize(list_sentences_pos_speeches)\n",
    "print(len(lemmatized_corpus_speeches))\n",
    "\n",
    "output = open('lemmatized_corpus_speeches.pkl', 'wb')\n",
    "pickle.dump(lemmatized_corpus_speeches, output)\n",
    "\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "# CRS reports\n",
    "list_sentences_pos_reports = get_pos(crs_reports[:2500])\n",
    "lemmatized_corpus_reports = lemmatize(list_sentences_pos_reports)\n",
    "print(len(lemmatized_corpus_reports))\n",
    "\n",
    "output = open('lemmatized_corpus_reports.pkl', 'wb')\n",
    "pickle.dump(lemmatized_corpus_reports, output)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the corpuses together (speeches, CRS, evidence words)\n",
    "import copy\n",
    "lemmatized_corpus_all = copy.deepcopy(lemmatized_corpus_speeches)\n",
    "lemmatized_corpus_all.extend(lemmatized_corpus_reports)\n",
    "tfidf_vecs_all, tfidf_df_all = make_tfidf(lemmatized_corpus_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411895, 1955)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('tfidf.pkl', 'wb')\n",
    "pickle.dump(tfidf_df_all, output, protocol = 4)\n",
    "\n",
    "output.close()\n",
    "\n",
    "output = open('tfidf_vecs.pkl', 'wb')\n",
    "pickle.dump(tfidf_vecs_all, output, protocol = 4)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_file = open('tfidf.pkl', 'rb')\n",
    "tfidf = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('tfidf_vecs.pkl', 'rb')\n",
    "tfidf_vec = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI with gensim\n",
    "\n",
    "The data is high-dimensional and comparisons of similarity are likely to be more fruitful with dimensionality reduction. I reduce the number of dimensions using LSI. Since I'm not interested in having interpretable topics per se, I chose LSI instead of NMF as it's faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "tfidf_corpus = matutils.Sparse2Corpus(tfidf_vec.transpose())\n",
    "\n",
    "id2word = corpora.Dictionary.from_corpus(tfidf_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the corpus\n",
    "output = open('tfidf_corpus.pkl', 'wb')\n",
    "pickle.dump(tfidf_corpus, output)\n",
    "\n",
    "output.close()\n",
    "\n",
    "# Pickle the id2word\n",
    "output = open('id2word.pkl', 'wb')\n",
    "pickle.dump(id2word, output)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('tfidf_corpus.pkl', 'rb')\n",
    "tfidf_corpus = pickle.load(pkl_file)\n",
    "\n",
    "pkl_file = open('id2word.pkl', 'rb')\n",
    "id2word = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel\n",
    "\n",
    "lsi = LsiModel(tfidf_corpus, id2word=id2word, num_topics=300)\n",
    "\n",
    "output = open('lsi.pkl', 'wb')\n",
    "pickle.dump(lsi, output)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_file = open('lsi.pkl', 'rb')\n",
    "lsi = pickle.load(pkl_file)\n",
    "\n",
    "\n",
    "# Load the vectors\n",
    "pkl_file = open('tfidf_corpus.pkl', 'rb')\n",
    "tfidf_corpus_speeches = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_corpus = lsi[tfidf_corpus]\n",
    "\n",
    "# List of document vectors\n",
    "#doc_vecs = [doc for doc in lsi_corpus_speeches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the lsi_corpus\n",
    "output = open('lsi_corpus.pkl', 'wb')\n",
    "pickle.dump(lsi_corpus, output)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating similarity\n",
    "\n",
    "I create a similarity matrix so that I get a similarity score for each speech with each other speech. I actually only interested in the mean similarity of each speech with all of the Royal Institution Christmas lectures as a whole.  This mean similarity score for each speech becomes the score for 'scientificness' or 'evidence-basedness'.\n",
    "\n",
    "The similarity with the list of science words is a simplier version of modelling the 'evidence-basedness' in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the model\n",
    "\n",
    "pkl_file = open('lsi.pkl', 'rb')\n",
    "lsi= pickle.load(pkl_file)\n",
    "\n",
    "# Load the vectors\n",
    "pkl_file = open('lsi_corpus.pkl', 'rb')\n",
    "lsi_corpus= pickle.load(pkl_file)\n",
    "\n",
    "# Load original dataframe if not loaded already\n",
    "pkl_file = open('tfidf.pkl', 'rb')\n",
    "tfidf = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "index = similarities.MatrixSimilarity(lsi_corpus, \n",
    "                                      num_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409395\n"
     ]
    }
   ],
   "source": [
    "# Calculate average similarity to CRS documents\n",
    "import pickle\n",
    "pkl_file = open('speeches_cleaned.pkl', 'rb')\n",
    "speeches_cleaned = pickle.load(pkl_file)\n",
    "\n",
    "no_docs_speeches = speeches_cleaned.shape[0]\n",
    "print(no_docs_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411895, 1955)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1955)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.iloc[no_docs_speeches:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs_docs = tfidf.iloc[no_docs_speeches:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 1955)\n",
      "(411895, 4455)\n"
     ]
    }
   ],
   "source": [
    "print(crs_docs.shape)\n",
    "for idx in crs_docs.index:\n",
    "    tfidf['crs_sim_{0}'.format((idx-1))] = index[lsi_corpus[(idx-1)]]\n",
    "print(tfidf.shape)\n",
    "crs_cols = [col for col in tfidf.columns if 'crs_sim_' in col]\n",
    "tfidf['crs_sim_avg'] = tfidf[crs_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_similarity = tfidf['crs_sim_avg']\n",
    "speeches_similarity = speeches_similarity[:no_docs_speeches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the lsi_corpus\n",
    "output = open('speeches_similarity.pkl', 'wb')\n",
    "pickle.dump(speeches_similarity, output)\n",
    "\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
